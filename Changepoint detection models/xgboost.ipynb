{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIR_white = pd.read_excel('CIR.xlsx', 'CIR_white')\n",
    "CIR_white['date'] = pd.to_datetime(CIR_white['date'], dayfirst=True)\n",
    "CIR_pink = pd.read_excel('CIR.xlsx', 'CIR_pink')\n",
    "CIR_pink['date'] = pd.to_datetime(CIR_pink['date'], dayfirst=True)\n",
    "CIR_red = pd.read_excel('CIR.xlsx', 'CIR_red')\n",
    "CIR_red['date'] = pd.to_datetime(CIR_red['date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to split all data into sequences. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, Y, train_batch=100):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train_batch, len(X)):\n",
    "        X_train.append(X[(i-train_batch):(i-1)])\n",
    "        Y_train.append(Y[i-1])\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White noise ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled = scaler.fit_transform(np.array(CIR_white['interest_rate']).reshape(-1, 1))\n",
    "scaled = scaled.reshape(len(CIR_white['interest_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = create_sequences(scaled, CIR_white['breakpoint'])\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, shuffle=False)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.1, shuffle=False)\n",
    "\n",
    "Y_train, Y_test = train_test_split(Y, test_size=0.2, shuffle=False)\n",
    "Y_train, Y_val = train_test_split(Y_train, test_size=0.1, shuffle=False)\n",
    "\n",
    "train_dates, test_dates = train_test_split(CIR_white['date'], test_size=0.2, shuffle=False)\n",
    "train_dates, val_dates = train_test_split(train_dates, test_size=0.1, shuffle=False)\n",
    "\n",
    "sample_weight = [1] * len(Y)\n",
    "for i in range (len(Y)):\n",
    "    if Y[i] == 1:\n",
    "        sample_weight[i] *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logloss = 9.046\n",
      "Best max depth = 2\n",
      "Best max leaves = 0\n",
      "Best learning rate = 1e-05\n",
      "Best accuracy score = 0.7380952380952381\n",
      "Best precision score = 0.7692307692307693\n",
      "Best recall score = 0.25\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "max_depth_values = range(2, 5)\n",
    "max_leaves_values = range(9)\n",
    "learning_rate_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "best_logloss = np.inf\n",
    "best_max_depth = 0\n",
    "best_max_leaves = 0\n",
    "best_learning_rate = 0\n",
    "best_accuracy = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    for max_leaves in max_leaves_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            model = XGBClassifier(n_estimators=100, max_depth=max_depth, max_leaves=max_leaves, learning_rate=learning_rate, objective='binary:logistic')\n",
    "            model.fit(X_train, Y_train, sample_weight=sample_weight[:len(Y_train)])\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_logloss = log_loss(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "\n",
    "            if val_logloss < best_logloss:\n",
    "                best_logloss = val_logloss\n",
    "                best_accuracy = accuracy_score(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "                best_precision = precision_score(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "                best_recall = recall_score(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "                best_max_depth = max_depth\n",
    "                best_learning_rate = learning_rate\n",
    "\n",
    "print(\"Best logloss = %.3f\" % best_logloss, sep=\"\")\n",
    "print(\"Best max depth = \", best_max_depth, sep=\"\")\n",
    "print(\"Best max leaves = \", best_max_leaves, sep=\"\")\n",
    "print(\"Best learning rate = \", best_learning_rate, sep=\"\")\n",
    "print(\"Best accuracy score = \", best_accuracy, sep=\"\")\n",
    "print(\"Best precision score = \", best_precision, sep=\"\")\n",
    "print(\"Best recall score = \", best_recall, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test logloss = 16.097\n",
      "Test accuracy score = 0.5339506172839507\n",
      "Test precision score = 0.297029702970297\n",
      "Test recall score = 0.2727272727272727\n"
     ]
    }
   ],
   "source": [
    "best_model = XGBClassifier(n_estimators=1000, max_depth=best_max_depth, max_leaves=best_max_leaves, learning_rate=best_learning_rate, objective='binary:logistic')\n",
    "best_model.fit(X_train, Y_train, sample_weight=sample_weight[:len(Y_train)])\n",
    "test_pred = best_model.predict(X_test)\n",
    "test_logloss = log_loss(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "test_accuracy = accuracy_score(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "test_precision = precision_score(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "test_recall = recall_score(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "\n",
    "print(\"Test logloss = %.3f\" % test_logloss, sep=\"\")\n",
    "print(\"Test accuracy score = \", test_accuracy, sep=\"\")\n",
    "print(\"Test precision score = \", test_precision, sep=\"\")\n",
    "print(\"Test recall score = \", test_recall, sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pink noise ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled = scaler.fit_transform(np.array(CIR_pink['interest_rate']).reshape(-1, 1))\n",
    "scaled = scaled.reshape(len(CIR_pink['interest_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = create_sequences(scaled, CIR_pink['breakpoint'])\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, shuffle=False)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.1, shuffle=False)\n",
    "\n",
    "Y_train, Y_test = train_test_split(Y, test_size=0.2, shuffle=False)\n",
    "Y_train, Y_val = train_test_split(Y_train, test_size=0.1, shuffle=False)\n",
    "\n",
    "train_dates, test_dates = train_test_split(CIR_pink['date'], test_size=0.2, shuffle=False)\n",
    "train_dates, val_dates = train_test_split(train_dates, test_size=0.1, shuffle=False)\n",
    "\n",
    "sample_weight = [1] * len(Y)\n",
    "for i in range (len(Y)):\n",
    "    if Y[i] == 1:\n",
    "        sample_weight[i] *= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logloss = 8.707\n",
      "Best max depth = 2\n",
      "Best max leaves = 0\n",
      "Best learning rate = 1e-05\n",
      "Best accuracy score = 0.7478991596638656\n",
      "Best precision score = 0.0\n",
      "Best recall score = 0.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "max_depth_values = range(2, 5)\n",
    "max_leaves_values = range(9)\n",
    "learning_rate_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "best_logloss = np.inf\n",
    "best_max_depth = 0\n",
    "best_max_leaves = 0\n",
    "best_learning_rate = 0\n",
    "best_accuracy = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    for max_leaves in max_leaves_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            model = XGBClassifier(n_estimators=100, max_depth=max_depth, max_leaves=max_leaves, learning_rate=learning_rate, objective='binary:logistic')\n",
    "            model.fit(X_train, Y_train, sample_weight=sample_weight[:len(Y_train)])\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_logloss = log_loss(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "\n",
    "            if val_logloss < best_logloss:\n",
    "                best_logloss = val_logloss\n",
    "                best_accuracy = accuracy_score(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "                best_precision = precision_score(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "                best_recall = recall_score(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "                best_max_depth = max_depth\n",
    "                best_learning_rate = learning_rate\n",
    "\n",
    "print(\"Best logloss = %.3f\" % best_logloss, sep=\"\")\n",
    "print(\"Best max depth = \", best_max_depth, sep=\"\")\n",
    "print(\"Best max leaves = \", best_max_leaves, sep=\"\")\n",
    "print(\"Best learning rate = \", best_learning_rate, sep=\"\")\n",
    "print(\"Best accuracy score = \", best_accuracy, sep=\"\")\n",
    "print(\"Best precision score = \", best_precision, sep=\"\")\n",
    "print(\"Best recall score = \", best_recall, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test logloss = 16.947\n",
      "Test accuracy score = 0.5093457943925234\n",
      "Test precision score = 0.0\n",
      "Test recall score = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "best_model = XGBClassifier(n_estimators=1000, max_depth=best_max_depth, max_leaves=best_max_leaves, learning_rate=best_learning_rate, objective='binary:logistic')\n",
    "best_model.fit(X_train, Y_train, sample_weight=sample_weight[:len(Y_train)])\n",
    "test_pred = best_model.predict(X_test)\n",
    "test_logloss = log_loss(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "test_accuracy = accuracy_score(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "test_precision = precision_score(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "test_recall = recall_score(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "\n",
    "print(\"Test logloss = %.3f\" % test_logloss, sep=\"\")\n",
    "print(\"Test accuracy score = \", test_accuracy, sep=\"\")\n",
    "print(\"Test precision score = \", test_precision, sep=\"\")\n",
    "print(\"Test recall score = \", test_recall, sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red noise ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled = scaler.fit_transform(np.array(CIR_red['interest_rate']).reshape(-1, 1))\n",
    "scaled = scaled.reshape(len(CIR_red['interest_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = create_sequences(scaled, CIR_red['breakpoint'])\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, shuffle=False)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.1, shuffle=False)\n",
    "\n",
    "Y_train, Y_test = train_test_split(Y, test_size=0.2, shuffle=False)\n",
    "Y_train, Y_val = train_test_split(Y_train, test_size=0.1, shuffle=False)\n",
    "\n",
    "train_dates, test_dates = train_test_split(CIR_red['date'], test_size=0.2, shuffle=False)\n",
    "train_dates, val_dates = train_test_split(train_dates, test_size=0.1, shuffle=False)\n",
    "\n",
    "sample_weight = [1] * len(Y)\n",
    "for i in range (len(Y)):\n",
    "    if Y[i] == 1:\n",
    "        sample_weight[i] *= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "max_depth_values = range(2, 5)\n",
    "max_leaves_values = range(9)\n",
    "learning_rate_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "best_logloss = np.inf\n",
    "best_max_depth = 0\n",
    "best_max_leaves = 0\n",
    "best_learning_rate = 0\n",
    "best_accuracy = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    for max_leaves in max_leaves_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            model = XGBClassifier(n_estimators=100, max_depth=max_depth, max_leaves=max_leaves, learning_rate=learning_rate, objective='binary:logistic')\n",
    "            model.fit(X_train, Y_train, sample_weight=sample_weight[:len(Y_train)])\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_logloss = log_loss(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "\n",
    "            if val_logloss < best_logloss:\n",
    "                best_logloss = val_logloss\n",
    "                best_accuracy = accuracy_score(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "                best_precision = precision_score(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "                best_recall = recall_score(Y_val, val_pred, sample_weight=sample_weight[len(Y_train):(len(Y_train)+len(Y_val))])\n",
    "                best_max_depth = max_depth\n",
    "                best_learning_rate = learning_rate\n",
    "\n",
    "print(\"Best logloss = %.3f\" % best_logloss, sep=\"\")\n",
    "print(\"Best max depth = \", best_max_depth, sep=\"\")\n",
    "print(\"Best max leaves = \", best_max_leaves, sep=\"\")\n",
    "print(\"Best learning rate = \", best_learning_rate, sep=\"\")\n",
    "print(\"Best accuracy score = \", best_accuracy, sep=\"\")\n",
    "print(\"Best precision score = \", best_precision, sep=\"\")\n",
    "print(\"Best recall score = \", best_recall, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(n_estimators=1000, max_depth=best_max_depth, max_leaves=best_max_leaves, learning_rate=best_learning_rate, objective='binary:logistic')\n",
    "best_model.fit(X_train, Y_train, sample_weight=sample_weight[:len(Y_train)])\n",
    "test_pred = best_model.predict(X_test)\n",
    "test_logloss = log_loss(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "test_accuracy = accuracy_score(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "test_precision = precision_score(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "test_recall = recall_score(Y_test, test_pred, sample_weight=sample_weight[len(Y_train)+len(Y_val):])\n",
    "\n",
    "print(\"Test logloss = %.3f\" % test_logloss, sep=\"\")\n",
    "print(\"Test accuracy score = \", test_accuracy, sep=\"\")\n",
    "print(\"Test precision score = \", test_precision, sep=\"\")\n",
    "print(\"Test recall score = \", test_recall, sep=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
